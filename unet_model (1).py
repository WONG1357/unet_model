# -*- coding: utf-8 -*-
"""unet model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ky0EeXuEkbJYGnXmr7Lk0iyHnrl0CV_r
"""

!pip install torch torchvision numpy matplotlib

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
import torch.nn.functional as F
import matplotlib.pyplot as plt
from google.colab import drive
import os
import random
from torchvision.transforms import functional as TF

# Define the DoubleConv module for two consecutive convolutions with batch normalization and ReLU
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)

# Define the Down module for downsampling with max pooling and DoubleConv
class Down(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)

# Define the Up module for upsampling with either bilinear interpolation or transposed convolution
class Up(nn.Module):
    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

# Define the OutConv module for the final convolution layer
class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)

# Define the complete U-Net architecture
class UNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=False):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear
        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        factor = 2 if bilinear else 1
        self.down4 = Down(512, 1024 // factor)
        self.up1 = Up(1024, 512 // factor, bilinear)
        self.up2 = Up(512, 256 // factor, bilinear)
        self.up3 = Up(256, 128 // factor, bilinear)
        self.up4 = Up(128, 64, bilinear)
        self.outc = OutConv(64, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return logits

# Custom dataset class with synchronized transformations for image and mask
class UltrasoundSegmentationDataset(Dataset):
    def __init__(self, X, y, is_train=False):
        self.X = X
        self.y = y
        self.is_train = is_train

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        # Convert numpy arrays to PIL Images to use torchvision transforms
        image = TF.to_pil_image(self.X[idx])
        mask = TF.to_pil_image(self.y[idx])

        # Convert back to tensors. This also scales images to [0, 1].
        image = TF.to_tensor(image)
        mask = TF.to_tensor(mask)

        return image, mask

# Added a separate `dice_score` function for metric evaluation
def dice_score(pred, target, smooth=1.):
    pred = torch.sigmoid(pred)
    # Flatten label and prediction tensors
    pred = pred.view(-1)
    target = target.view(-1)
    intersection = (pred * target).sum()
    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)
    return dice

def dice_loss(pred, target, smooth=1):
    # Dice loss is 1 - Dice Score
    score = dice_score(pred, target, smooth)
    return 1 - score

# Define combined loss function (BCE + Dice)
class CombinedLoss(nn.Module):
    def __init__(self):
        super(CombinedLoss, self).__init__()
        self.bce = nn.BCEWithLogitsLoss()

    def forward(self, pred, target):
        bce_loss_val = self.bce(pred, target)
        dice_loss_val = dice_loss(pred, target)
        return bce_loss_val + dice_loss_val

if __name__ == "__main__":
    drive.mount('/content/drive')

    base_dir = "/content/drive/MyDrive/intern RF tmr ddl again week 5"

    X_train = np.load(f'{base_dir}/X_train.npy')
    y_train = np.load(f'{base_dir}/y_train.npy')
    X_val = np.load(f'{base_dir}/X_val.npy')
    y_val = np.load(f'{base_dir}/y_val.npy')
    X_test = np.load(f'{base_dir}/X_test.npy')
    y_test = np.load(f'{base_dir}/y_test.npy')

    print(f"Data: X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
    print(f"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}")
    print(f"X_test shape: {X_test.shape}, y_test shape{ y_test.shape}")

    if X_train.shape[0] == 0 or X_val.shape[0] == 0 or X_test.shape[0] == 0:
        raise ValueError("One or more datasets are empty. Check preprocessing output.")

    # Create datasets using the corrected Dataset class
    train_dataset = UltrasoundSegmentationDataset(X_train, y_train, is_train=True)
    val_dataset = UltrasoundSegmentationDataset(X_val, y_val, is_train=False)
    test_dataset = UltrasoundSegmentationDataset(X_test, y_test, is_train=False)

    batch_size = 16
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)
    test_loader = DataLoader(test_dataset, batch_size=batch_size)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(n_channels=1, n_classes=1, bilinear=True).to(device)

    criterion = CombinedLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-3)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=10)

    num_epochs = 150
    best_val_loss = float('inf')
    best_val_dice_score = 0.0
    patience = 25
    trigger_times = 0
    accumulation_steps = 4
    optimizer.zero_grad()

    for epoch in range(num_epochs):
        model.train()
        train_loss = 0.0
        train_dice_score = 0.0
        for i, (images, masks) in enumerate(train_loader):
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            loss = criterion(outputs, masks) / accumulation_steps
            score = dice_score(outputs, masks)
            loss.backward()
            train_loss += loss.item() * accumulation_steps
            train_dice_score += score.item()

            if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):
                optimizer.step()
                optimizer.zero_grad()

        model.eval()
        val_loss = 0.0
        val_dice_score = 0.0
        with torch.no_grad():
            for images, masks in val_loader:
                images, masks = images.to(device), masks.to(device)
                outputs = model(images)
                loss = criterion(outputs, masks)
                score = dice_score(outputs, masks)
                val_loss += loss.item()
                val_dice_score += score.item()

        train_loss /= len(train_loader)
        train_dice_score /= len(train_loader)
        val_loss /= len(val_loader)
        val_dice_score /= len(val_loader)

        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Dice Score: {train_dice_score:.4f}, '
              f'Val Loss: {val_loss:.4f}, Val Dice Score: {val_dice_score:.4f}')

        if val_dice_score > best_val_dice_score:
            best_val_dice_score = val_dice_score
            best_val_loss = val_loss
            trigger_times = 0
            torch.save(model.state_dict(), f'/content/drive/MyDrive/internship models/ordinary unet model/rectus femoris /best_model_all_patients.pth')
            print(f"New best Dice Score: {best_val_dice_score:.4f}. Saving model...")
        elif val_loss < best_val_loss:
            best_val_loss = val_loss
            trigger_times = 0
            torch.save(model.state_dict(), f'/content/drive/MyDrive/internship models/ordinary unet model/rectus femoris /best_model_all_patients.pth')
            print(f"New best validation loss: {best_val_loss:.4f}. Saving model...")
        else:
            trigger_times += 1
            if trigger_times >= patience:
                print(f'Early stopping triggered after {patience} epochs without improvement.')
                break


        scheduler.step(val_loss)

    print("Loading best model for testing...")
    model.load_state_dict(torch.load(f'/content/drive/MyDrive/internship models/ordinary unet model/rectus femoris /best_model_all_patients.pth'))
    model.eval()
    test_loss = 0.0
    test_dice_score = 0.0
    predictions = []
    with torch.no_grad():
        for images, masks in test_loader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            loss = criterion(outputs, masks)
            score = dice_score(outputs, masks)
            test_loss += loss.item()
            test_dice_score += score.item()
            predictions.append(torch.sigmoid(outputs).cpu().numpy())

    test_loss /= len(test_loader)
    test_dice_score /= len(test_loader)
    predictions = np.concatenate(predictions, axis=0)
    print(f'Test Loss: {test_loss:.4f}, Test Dice Score: {test_dice_score:.4f}')

    num_examples = min(5, len(X_test))
    indices = np.random.choice(len(X_test), num_examples, replace=False)
    for i, idx in enumerate(indices):
        plt.figure(figsize=(12, 4))
        plt.subplot(1, 3, 1)
        plt.title('Input Image')
        plt.imshow(X_test[idx].squeeze(), cmap='gray')
        plt.axis('off')
        plt.subplot(1, 3, 2)
        plt.title('Predicted Mask')
        plt.imshow(predictions[idx].squeeze() > 0.5, cmap='gray')
        plt.axis('off')
        plt.subplot(1, 3, 3)
        plt.title('Ground Truth Mask')
        plt.imshow(y_test[idx].squeeze(), cmap='gray')
        plt.axis('off')
        plt.tight_layout()
        output_plot_path = f'{base_dir}/test_result_all_patients_{i+1}.png'
        plt.savefig(output_plot_path)
        plt.show()
        print(f"Saved visualization to {output_plot_path}")